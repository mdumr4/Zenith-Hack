# local_llm.py

def complete(text_context):
    # Team B: Use onnxruntime to run quantized model
    return "suggestion"
